flink 容错机制 容错机制 容错机制
①一致性检查点 checkpoint  所有任务的一分快照 checkpoint是由JobManager管理的并且是保证每个分区都必须完成对应数据的状态更新才会进行checkpoint操作

故障恢复机智的核心
有状态的应用的一致检查点，其实就是所有任务的状态，在某一个时间点的一份拷贝，这个时间触发点，就是
所有任务处理完一个相同的输入数据的时候

一般思想： 当前数据 - 当前状态 - 当前处理的位置  但是状态又很多，位置又很多，这个记录下来很细，
flink觉得太复杂，就没有使用(主要是考虑运行时异常，如宕机)

flink思想：只要新的数据导致状态全部更新，我才更新一份快照存放在stateBackend中，此时如果在中间出现异常，从新来过，状态重置
当然每一个数据的不同状态不需要等待所有的状态更新完才继续下一个数据的状态更新。(将检查点的保存和数据的处理分开)

checkpoint数据结构：checkpoint采用了一种类似一种barrier的数据结构，便于将一条流上的数据按照不同的检查点分开


每次状态更新完后，就插入一个小小的标记，相当于一个类似Watermark的流失数据，

②从检查点恢复状态

见①的flink思想

③flink检查点算法  ---- 基于chady-lamport 算法的分布式快照


见①的flink思想以及数据结构

问题一：如何在分布式系统中告诉其他分区下游任务我这边数据的处理状况 ----  直接将barrier广播出去给各个分区都有一份，
一个barrier将两个数据或者两组数据分开，上一个数据的所有状态更新完了，才会加入一个barrier后并将快照更新，因为对我本阶段任务来说，我并不知道自己
下一个阶段的分区是啥，如果说先知道自己是哪一个分区，在把我的数据给对应的分区，显然不是现实的做法

问题二：当下游任务会将上游任务的结果进行重新分区，那么会出现这样一种问题，就是当一个分区内所有的barrier都到了，那么是否要
做checkpoint呢，因为这个我们是说，来了barrier就要做checkpoint，但是每个分区处理数据速度是不一样的，肯定有先到后到，显然直接做
checkpoint是不合理的，因为你拿着本不属于你的barrier为别人做决定，怎么可能呢，别人的具体是否完成了数据的状态更新，你怎么知道，所以做
快照的前提是上一个任务对应快照的barrier对应的本阶段任务的状态更新都要做完了才能做快照，怎么要保证呢，这个就是需要本阶段所有分区
都收到了上一阶段的广播出来的barrier，从任务的视角而非分区的视角来看，就是说该阶段任务所有的数据都完成了。那么在中间的这个阶段，在未达到这种状态，
那么会把各个barrier缓存起来，由于数据的处理和barrier之间分开操作，那么就是说这时候数据的状态的更新还是在继续干的

④保存点 savepoint

一种特殊的checkpoint,这个是需要外部设置的，
不仅可以存盘数据，也可以更新应用程序

将保存的数据迁移到高版本的flink
暂停和重启






补充： jobManager的作用
触发一个checkpoint的操作，会把checkpoint中所有任务状态的拓扑结构保存下来

flink流式反压机制----控制数据流的合理流速
当数据流不均衡(反压)，为了解决这个问题，spark用了PID(控制工程的比例微分积分->动态闭环控制系统)

Flink是根据每一个分区的slot的缓存区根据不同任务进行分配比例，每一个下游任务区域会给下游任务区域一个credit(信任度)，信任度越大，能发的数据流速越大